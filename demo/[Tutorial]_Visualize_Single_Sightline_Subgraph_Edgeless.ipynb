{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the data\n",
    "\n",
    "__Author:__ Ji Won Park (@jiwoncpark)\n",
    "\n",
    "__Created:__ 3/08/2021\n",
    "\n",
    "__Last run:__ 4/12/2021\n",
    "\n",
    "__Goals:__\n",
    "We visualize the input graph.\n",
    "\n",
    "__Before_running:__\n",
    "Generate the labels with explicit kappa sampling (moving the constituent halos around in each sightline field of view (FOV) multiple times and evaluating kappa at the center), e.g.\n",
    "```python\n",
    "kappa_sampler = CosmoDC2Raytracer(in_dir=IN_DIR,\n",
    "                                  out_dir='../kappa_sampling',\n",
    "                                  fov=0.85,\n",
    "                                  healpix=10450,\n",
    "                                  n_sightlines=1000,  # keep this small\n",
    "                                  mass_cut=11.0,\n",
    "                                  n_kappa_samples=1000)\n",
    "kappa_sampler.parallel_raytrace()\n",
    "kappa_sampler.apply_calibration()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that we won't have to explicitly sample kappa every time, we will use Gaussian process regression to infer the spread in kappa for the weighted sum of masses of each sightline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, we raytrace with halos in a smaller aperture than we query to get the graph. For illustrating the galaxy-halo connection, we'll make the aperture sizes the same. (The `aperture_size` kwarg for `CosmoDC2Graph`, which expects a radius, is half the `fov` kwarg for `CosmoDC2Raytracer`, which expects a diameter.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 10 sightline(s) in 0.11 min.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10/10 [02:01<00:00, 12.16s/it]\n"
     ]
    }
   ],
   "source": [
    "from n2j.trainval_data.raytracers.cosmodc2_raytracer import CosmoDC2Raytracer\n",
    "\n",
    "IN_DIR = '../n2j/data'  # where raw data lies\n",
    "TRAIN_HP = [10326]\n",
    "N_TRAIN = 10\n",
    "BATCH_SIZE = min(N_TRAIN//5, 25)\n",
    "KAPPA_DIFF = 1.0  # arcsec\n",
    "fov = 1.35  # diameter of fov in arcmin\n",
    "    \n",
    "# Use this to infer the mean kappa contribution of new sightlines\n",
    "for hp in TRAIN_HP:\n",
    "    train_Y_generator = CosmoDC2Raytracer(in_dir=IN_DIR,\n",
    "                                          out_dir=f'../demo_Y_{hp}',\n",
    "                                          # kappa_sampling_dir='../kappa_sampling',\n",
    "                                          fov=fov*2.0,\n",
    "                                          healpix=hp,\n",
    "                                          n_sightlines=N_TRAIN,\n",
    "                                          mass_cut=11.0,\n",
    "                                          n_kappa_samples=1000,\n",
    "                                          seed=123)  # no sampling\n",
    "    train_Y_generator.parallel_raytrace(n_cores=4)\n",
    "    train_Y_generator.apply_calibration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build graphs for these 100 sightlines we just computed labels for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from n2j.trainval_data.graphs.cosmodc2_graph import CosmoDC2Graph\n",
    "# Features to compile\n",
    "features = ['ra', 'dec', 'galaxy_id', 'redshift']\n",
    "features += ['ra_true', 'dec_true', 'redshift_true']\n",
    "features += ['ellipticity_1_true', 'ellipticity_2_true']\n",
    "features += ['bulge_to_total_ratio_i', 'ellipticity_1_bulge_true', 'ellipticity_1_disk_true',\n",
    "             'ellipticity_2_bulge_true', 'ellipticity_2_disk_true', ]\n",
    "features += ['shear1', 'shear2', 'convergence']\n",
    "features += ['size_bulge_true', 'size_disk_true', 'size_true']\n",
    "features += ['mag_{:s}_lsst'.format(b) for b in 'ugrizY']\n",
    "\n",
    "train_XY = CosmoDC2Graph(in_dir=IN_DIR, \n",
    "                         healpixes=TRAIN_HP, \n",
    "                         raytracing_out_dirs=[f'../demo_Y_{hp}' for hp in TRAIN_HP], \n",
    "                         aperture_size=fov*0.5,\n",
    "                         n_data=[N_TRAIN], \n",
    "                         features=features, \n",
    "                         stop_mean_std_early=False,\n",
    "                         n_cores=4,\n",
    "                         out_dir='../demo_X')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which sightlines should we plot? Maybe we want to check out the overdense ones, with high $\\kappa$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N_TRAIN):\n",
    "    if train_XY[i].y[0, 0] > 0.05:\n",
    "        print(i, train_XY[i].y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now color the nodes by the redshift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointings = train_XY.Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_i = 43\n",
    "sample_data = train_XY[data_i]\n",
    "z_src = pointings.iloc[data_i]['z']\n",
    "print(z_src)\n",
    "z = sample_data.x[:, 3].numpy()\n",
    "z[0] = z_src\n",
    "plt.hist(z, bins=np.linspace(0, 2.5, 20))\n",
    "plt.axvline(z_src, color='tab:red', label='Source z')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '/home/jwp/stage/sl/n2j/demo_Y_10326'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pointings\n",
    "pointings_cols = ['kappa', 'gamma1', 'gamma2']\n",
    "pointings_cols += ['galaxy_id', 'ra', 'dec', 'z', 'eps']\n",
    "pointings_cols.sort()\n",
    "pointings_arr = np.load(os.path.join(out_dir, 'sightlines.npy'))\n",
    "pointings = pd.DataFrame(pointings_arr, columns=pointings_cols)\n",
    "sightline = pointings.iloc[data_i]\n",
    "cos_factor = np.cos(np.deg2rad(sightline['dec']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_networkx\n",
    "import torch\n",
    "import networkx as nx\n",
    "import matplotlib.cm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can additionally scale the node size by the (inverse) i-band magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "cmap = matplotlib.cm.get_cmap('jet')\n",
    "sample_data = train_XY[data_i]\n",
    "# Remove mag > 25.3\n",
    "mag_idx = features.index('mag_i_lsst')\n",
    "mask = sample_data.x[:, mag_idx] < 30\n",
    "# Put ra, dec in arcsec\n",
    "ra_idx = features.index('ra_true')\n",
    "dec_idx = features.index('dec_true')\n",
    "print(ra_idx, dec_idx)\n",
    "sample_data.x[:, ra_idx] = sample_data.x[:, ra_idx]*60.0*60.0/np.cos(np.deg2rad(sample_data.x[:, 1]))  # remove cos factor\n",
    "sample_data.x[:, dec_idx] = sample_data.x[:, dec_idx]*60.0*60.0\n",
    "# Update sample_data\n",
    "sample_data.x = sample_data.x[mask, :]\n",
    "sample_data.edge_index = torch.arange(6).reshape(2, 3)\n",
    "sample_networkx = to_networkx(sample_data)\n",
    "n_nodes = sample_data.x.shape[0]\n",
    "# Color by redshift\n",
    "z = sample_data.x[:, 3].numpy()\n",
    "z[0] = pointings.iloc[data_i]['z']\n",
    "scaled_z = (z - z.min())/(z.max() - z.min())  # scale 0 to 1 for colormap\n",
    "node_color = cmap(scaled_z)\n",
    "# Make brighter nodes bigger\n",
    "mag = -sample_data.x[:, -3].numpy()\n",
    "mag[0] = np.mean(mag[1:])\n",
    "node_size = (mag - mag.min())/(mag.max() - mag.min())*50 + 10\n",
    "#node_size[0] = 50\n",
    "print(\"min max ra\", sample_data.x[:, 4].min(), sample_data.x[:, 4].max())\n",
    "nx.draw(sample_networkx, pos=dict(zip(range(n_nodes), sample_data.x[:, [4, 5]].tolist())),\n",
    "        width=0.2, edge_color='tab:gray', arrowsize=0.0, alpha=1.0, \n",
    "        node_color=node_color, node_size=node_size, ax=ax)\n",
    "ax.scatter([0], [0], marker='x', color='k')\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=z.min(), vmax=z.max()))\n",
    "sm.set_array([])\n",
    "limits = plt.axis('on') # turns on axis\n",
    "ax.tick_params(left=True, bottom=True, labelleft=True, labelbottom=True)\n",
    "#ax.set_xlim([-40.5, 40.5])\n",
    "#ax.set_ylim([-40.5, 40.5])\n",
    "fig.colorbar(sm)\n",
    "\n",
    "print(sample_data.x.shape, sample_data.edge_index.shape)\n",
    "print(sample_data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "halos_cols = ['ra', 'ra_diff', 'dec', 'dec_diff', 'z', 'dist']\n",
    "halos_cols += ['eff', 'halo_mass', 'stellar_mass', 'Rs', 'alpha_Rs']\n",
    "halos_cols += ['galaxy_id']\n",
    "halos_cols.sort()\n",
    "\n",
    "halos_path_fmt = os.path.join(out_dir, 'halos_los={0:07d}_id=*.npy')\n",
    "halos_path = glob.glob(halos_path_fmt.format(data_i))[0]\n",
    "halos_arr = np.load(halos_path)\n",
    "halos = pd.DataFrame(halos_arr, columns=halos_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lenstronomy.LensModel.lens_model import LensModel\n",
    "from astropy.cosmology import WMAP7   # WMAP 7-year cosmology\n",
    "import n2j.trainval_data.utils.raytracing_utils as ru\n",
    "import n2j.trainval_data.utils.halo_utils as hu\n",
    "import n2j.trainval_data.utils.coord_utils as cu\n",
    "\n",
    "\n",
    "n_halos = halos.shape[0]\n",
    "# Instantiate multi-plane lens model\n",
    "lens_model = LensModel(lens_model_list=['NFW']*n_halos,\n",
    "                       z_source=sightline['z'],\n",
    "                       lens_redshift_list=halos['z'].values,\n",
    "                       multi_plane=True,\n",
    "                       cosmo=WMAP7,\n",
    "                       observed_convention_index=[])\n",
    "halos['center_x'] = halos['ra_diff']*3600.0  # deg to arcsec\n",
    "halos['center_y'] = halos['dec_diff']*3600.0\n",
    "nfw_kwargs = halos[['Rs', 'alpha_Rs', 'center_x', 'center_y']].to_dict('records')\n",
    "uncalib_kappa = lens_model.kappa(0.0, 0.0, nfw_kwargs,\n",
    "                                 diff=KAPPA_DIFF,\n",
    "                                 diff_method='square')\n",
    "uncalib_gamma1, uncalib_gamma2 = lens_model.gamma(0.0, 0.0, nfw_kwargs,\n",
    "                                                  diff=KAPPA_DIFF,\n",
    "                                                  diff_method='square')\n",
    "# Log the uncalibrated shear/convergence and the weighted sum of halo masses\n",
    "w_mass_sum = np.log10(np.sum(halos['eff'].values*halos['halo_mass'].values))\n",
    "new_row_data = dict(idx=[data_i],\n",
    "                    kappa=[uncalib_kappa],\n",
    "                    gamma1=[uncalib_gamma1],\n",
    "                    gamma2=[uncalib_gamma2],\n",
    "                    weighted_mass_sum=[w_mass_sum],\n",
    "                    )\n",
    "# Optionally map the uncalibrated shear and convergence on a grid\n",
    "\n",
    "hu.get_kappa_map(lens_model, nfw_kwargs, fov,\n",
    "                 'kappa_map.npy',\n",
    "                 KAPPA_DIFF,\n",
    "                #x_grid=np.arange(-fov*0.5, fov*0.5, 0.1/60.0)*60.0,\n",
    "                 x_grid=np.arange(-54, 54+0.1/60.0, 0.1),\n",
    "                y_grid=np.arange(-fov*0.5, fov*0.5, 0.1/60.0)*60.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "halos.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "#plt.close('all')\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "import lenstronomy.Util.param_util as param_util\n",
    "\n",
    "kappa_map = np.load('kappa_map.npy')\n",
    "min_k = np.min(kappa_map)\n",
    "print(\"Minmax: \", np.min(kappa_map), np.max(kappa_map))\n",
    "print(np.mean(kappa_map[kappa_map<0.4]))\n",
    "#kappa_map[kappa_map<0] = np.nan\n",
    "#print(\"Number of negative pixels: \", (~np.isfinite(kappa_map)).sum())\n",
    "ax.scatter(0, 0, marker='x', color='k')\n",
    "#some_halos = halos[halos['eff'] < 0.5]\n",
    "if False:  # plot halo locations\n",
    "    plt.scatter(halos['ra_diff']*60.0*60.0, halos['dec_diff']*60.0*60.0, \n",
    "                marker='x', color='white', s=np.log10(halos['halo_mass'].values)*4)\n",
    "if True:\n",
    "    plt.scatter(sample_data.x[:, 4], sample_data.x[:, 5], marker='*', color='white')\n",
    "cmap = copy.copy(plt.cm.viridis)\n",
    "cmap.set_bad((1, 0, 0, 1))\n",
    "im = ax.imshow(kappa_map, extent=[-54, 54, -fov*60.0*0.5, fov*60.0*0.5], \n",
    "               origin='lower', \n",
    "               cmap=cmap,\n",
    "              #vmin=0.08,\n",
    "              #vmax=1.\n",
    "              )\n",
    "\n",
    "#im = ax.imshow(phi, extent=[-fov*60.0*0.5, fov*60.0*0.5, -fov*60.0*0.5, fov*60.0*0.5], origin='lower', cmap=cmap)\n",
    "#ax.set_xticks(np.linspace(-fov*60.0*0.5, fov*60.0*0.5, 10))\n",
    "#ax.set_yticks(np.linspace(-fov*60.0*0.5, fov*60.0*0.5, 10))\n",
    "#plt.xlabel(r\"'' \")\n",
    "#plt.ylabel(r\"'' \")\n",
    "#ax.set_xlim([-40.5, 40.5])\n",
    "#ax.set_ylim([-40.5, 40.5])\n",
    "ax.set_xlabel('asec')\n",
    "ax.set_ylabel('asec')\n",
    "fig.colorbar(im, fraction=0.046, pad=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.arange(30)\n",
    "yy = np.arange(20)\n",
    "\n",
    "xx, yy = np.meshgrid(xx, yy)\n",
    "\n",
    "z = (xx - 2*yy)**2.0\n",
    "    \n",
    "#grid[0, 1] = 0.0\n",
    "\n",
    "plt.imshow(z, origin='lower')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(-2*20)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (n2j)",
   "language": "python",
   "name": "n2j"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
