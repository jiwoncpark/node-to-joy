{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the data\n",
    "\n",
    "__Author:__ Ji Won Park (@jiwoncpark)\n",
    "\n",
    "__Created:__ 3/08/2021\n",
    "\n",
    "__Last run:__ 4/12/2021\n",
    "\n",
    "__Goals:__\n",
    "We visualize the input graph.\n",
    "\n",
    "__Before_running:__\n",
    "Generate the labels with explicit kappa sampling (moving the constituent halos around in each sightline field of view (FOV) multiple times and evaluating kappa at the center), e.g.\n",
    "```python\n",
    "kappa_sampler = CosmoDC2Raytracer(in_dir=IN_DIR,\n",
    "                                  out_dir='../kappa_sampling',\n",
    "                                  fov=0.85,\n",
    "                                  healpix=10450,\n",
    "                                  n_sightlines=1000,  # keep this small\n",
    "                                  mass_cut=11.0,\n",
    "                                  n_kappa_samples=1000)\n",
    "kappa_sampler.parallel_raytrace()\n",
    "kappa_sampler.apply_calibration()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that we won't have to explicitly sample kappa every time, we will use Gaussian process regression to infer the spread in kappa for the weighted sum of masses of each sightline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from n2j.trainval_data.raytracers.cosmodc2_raytracer import CosmoDC2Raytracer\n",
    "\n",
    "IN_DIR = '../n2j/data'  # where raw data lies\n",
    "TRAIN_HP = [10327]\n",
    "N_TRAIN = 1000\n",
    "BATCH_SIZE = min(N_TRAIN//5, 25)\n",
    "    \n",
    "# Use this to infer the mean kappa contribution of new sightlines\n",
    "for hp in TRAIN_HP:\n",
    "    train_Y_generator = CosmoDC2Raytracer(in_dir=IN_DIR,\n",
    "                                          out_dir=f'../demo_Y_{hp}',\n",
    "                                          kappa_sampling_dir='../kappa_sampling',\n",
    "                                          fov=0.85,\n",
    "                                          healpix=hp,\n",
    "                                          n_sightlines=N_TRAIN,\n",
    "                                          mass_cut=11.0,\n",
    "                                          n_kappa_samples=0)  # no sampling\n",
    "    train_Y_generator.parallel_raytrace()\n",
    "    train_Y_generator.apply_calibration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build graphs for these 100 sightlines we just computed labels for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from n2j.trainval_data.graphs.cosmodc2_graph import CosmoDC2Graph\n",
    "# Features to compile\n",
    "features = ['ra', 'dec', 'galaxy_id', 'redshift']\n",
    "features += ['ra_true', 'dec_true', 'redshift_true']\n",
    "features += ['ellipticity_1_true', 'ellipticity_2_true']\n",
    "features += ['bulge_to_total_ratio_i', 'ellipticity_1_bulge_true', 'ellipticity_1_disk_true',\n",
    "             'ellipticity_2_bulge_true', 'ellipticity_2_disk_true', ]\n",
    "features += ['shear1', 'shear2', 'convergence']\n",
    "features += ['size_bulge_true', 'size_disk_true', 'size_true']\n",
    "features += ['mag_{:s}_lsst'.format(b) for b in 'ugrizY']\n",
    "\n",
    "train_XY = CosmoDC2Graph(in_dir=IN_DIR, \n",
    "                         healpixes=TRAIN_HP, \n",
    "                         raytracing_out_dirs=[f'../demo_Y_{hp}' for hp in TRAIN_HP], \n",
    "                         aperture_size=1.0,\n",
    "                         n_data=[100], \n",
    "                         features=features, \n",
    "                         stop_mean_std_early=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which sightlines should we plot? Maybe we want to check out the overdense ones, with high $\\kappa$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    if train_XY[i].y[0, 0] > 0.05:\n",
    "        print(i, train_XY[i].y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now color the nodes by the redshift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointings = train_XY.Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_i = 89\n",
    "sample_data = train_XY[data_i]\n",
    "z_src = pointings.iloc[data_i]['z']\n",
    "print(z_src)\n",
    "z = sample_data.x[:, 3].numpy()\n",
    "z[0] = z_src\n",
    "plt.hist(z, bins=np.linspace(0, 2.5, 20))\n",
    "plt.axvline(z_src, color='tab:red', label='Source z')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_networkx\n",
    "import torch\n",
    "import networkx as nx\n",
    "import matplotlib.cm\n",
    "\n",
    "data_i = 89\n",
    "cmap = matplotlib.cm.get_cmap('jet')\n",
    "sample_data = train_XY[data_i]\n",
    "sample_data.edge_index = torch.arange(6).reshape(2, 3)\n",
    "sample_networkx = to_networkx(sample_data)\n",
    "n_nodes = sample_data.x.shape[0]\n",
    "# Color by redshift\n",
    "z = sample_data.x[:, 3].numpy()\n",
    "z[0] = pointings.iloc[data_i]['z']\n",
    "scaled_z = (z - z.min())/(z.max() - z.min())  # scale 0 to 1 for colormap\n",
    "node_color = cmap(scaled_z)\n",
    "# Make sightline node bigger\n",
    "node_size = np.ones(n_nodes)*5\n",
    "node_size[0] = 20\n",
    "nx.draw(sample_networkx, pos=dict(zip(range(n_nodes), sample_data.x[:, 4:6].tolist())),\n",
    "        width=0.2, alpha=1.0, arrowsize=0.0,\n",
    "        node_color=node_color, node_size=node_size)\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=z.min(), vmax=z.max()))\n",
    "sm.set_array([])\n",
    "plt.colorbar(sm)\n",
    "\n",
    "print(sample_data.x.shape, sample_data.edge_index.shape)\n",
    "print(sample_data.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can additionally scale the node size by the (inverse) i-band magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "data_i = 89\n",
    "cmap = matplotlib.cm.get_cmap('jet')\n",
    "sample_data = train_XY[data_i]\n",
    "sample_data.edge_index = torch.arange(6).reshape(2, 3)\n",
    "sample_networkx = to_networkx(sample_data)\n",
    "n_nodes = sample_data.x.shape[0]\n",
    "# Color by redshift\n",
    "z = sample_data.x[:, 3].numpy()\n",
    "z[0] = pointings.iloc[data_i]['z']\n",
    "scaled_z = (z - z.min())/(z.max() - z.min())  # scale 0 to 1 for colormap\n",
    "node_color = cmap(scaled_z)\n",
    "# Make brighter nodes bigger\n",
    "mag = -sample_data.x[:, -3].numpy()\n",
    "mag[0] = np.mean(mag[1:])\n",
    "node_size = (mag - mag.min())/(mag.max() - mag.min())*30 + 5\n",
    "node_size[0] = 50\n",
    "\n",
    "nx.draw(sample_networkx, pos=dict(zip(range(n_nodes), sample_data.x[:, 4:6].tolist())),\n",
    "        width=0.2, edge_color='tab:gray', arrowsize=0.0, alpha=1.0, \n",
    "        node_color=node_color, node_size=node_size)\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=z.min(), vmax=z.max()))\n",
    "sm.set_array([])\n",
    "plt.colorbar(sm)\n",
    "\n",
    "print(sample_data.x.shape, sample_data.edge_index.shape)\n",
    "print(sample_data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (n2j)",
   "language": "python",
   "name": "n2j"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
